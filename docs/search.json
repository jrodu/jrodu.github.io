[
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Jordan Rodu Department of Statistics The University of Virginia Charlottesville, VA\n\n\n\nPhD in Statistics, 2014\nThe Wharton School at the University of Pennsylvania, Philadelphia, PA\nMA in Orchestral Conducting, 2006\nBard College, Annandale-on-Hudson, NY\nBA in Mathematics, 2005\nWilliams College, Williamstown, MA\n\nmore soon…"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "My blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Jordan Rodu Department of Statistics The University of Virginia Charlottesville, VA\nI am an assistant professor in the Department of Statistics at the University of Virginia. My research interests include statistical visualization, theory of reasoning with data, and time series. I spend a lot of time thinking about the fuzzy space between statistics and machine learning/AI."
  },
  {
    "objectID": "index_bak.html",
    "href": "index_bak.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Jordan Rodu is an assistant professor of Statistics at the University of Virginia. His primary interests include statistical visualization, methods of reasoning with data, and time series."
  },
  {
    "objectID": "index_bak.html#education",
    "href": "index_bak.html#education",
    "title": "Jordan Rodu",
    "section": "Education",
    "text": "Education\nPhD, Statistics, 2014\nThe Wharton School at the University of Pennsylvania\nPhiladelphia, PA\nBA, Mathematics, 2005\nWilliams College\nWilliamstown, MA"
  },
  {
    "objectID": "index_bak.html#experience",
    "href": "index_bak.html#experience",
    "title": "Jordan Rodu",
    "section": "Experience",
    "text": "Experience\nAssistant Professor\nDepartment of Statistics\nUniversity of Virginia, Charlottesville VA\n2017-present\nVisiting Assistant Professor\nDepartment of Statistics\nCarnegie Mellon University, Pittsburgh, PA\n2014-2017"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Publications\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n  \n    Jordan Rodu, Michael Baiocchi (2023) When black box algorithms are (not) appropriate. Observational Studies.\n  \n  \n    Alexandra F Dejong Lempke, Stephanie L Stephens, Pamela N Fish, Xavier D Thompson, Joseph M Hart, David J Hryvniak, Jordan Rodu, Jay Hertel (2023) Running-Related Injuries Captured Using Wearable Technology during a Cross-Country Season: A Preliminary Study. Translational Journal of the ACSM 8(1):e000217.\n  \n  \n    Alexandra F Dejong Lempke, Stephanie L Stephens, Pamela N Fish, Xavier D Thompson, Joseph M Hart, David J Hryvniak, Jordan Rodu, Jay Hertel (2022) Sensor-based gait training to reduce contact time for runners with exercise-related lower leg pain: a randomised controlled trial. BMJ Open Sport and Exercise Medicine 3;8(4):e001293.\n  \n  \n    Sean A Klein, Michael Baiocchi, Jordan Rodu, Heather Baker, Erica Rosemond, Jamie Mihoko Doyle (2022) An analysis of the Clinical and Translational Science Award pilot project portfolio using data from Research Performance Progress Reports. Journal of Clinical and Translational Science 18;6(1):e113.\n  \n  \n    Alexandra F Dejong Lempke, Joseph M Hart, David J Hryvniak, Jordan Rodu, Jay Hertel (2022) Prospective running assessments among division I cross-country athletes. Physical Therapy in Sport Volume 55.\n  \n  \n    Alexandra F Dejong Lempke, Joseph M Hart, David J Hryvniak, Jordan Rodu, Jay Hertel (2021) Use of wearable sensors to identify biomechanical alterations in runners with Exercise-Related lower leg pain. Journal of Biomechanics Volume 126.\n  \n  \n    Jordan Rodu, Karen Kafadar (2021) The q–q Boxplot. Journal of Computational and Graphical Statistics 31:1, 26-39.\n  \n  \n    Jordan Rodu (2021) Text Analytics: Advances and Challenges Domenica Fioredistella Iezzi, Damon Mayaffre and Michelangelo Misuraca Springer, 2020, xi + 302 pages, £95.50, eBook ISBN: 978-3-030-52680-1. International Statistical Review Volume 89, Issue 2.\n  \n  \n    Michael Baiocchi, Jordan Rodu (2021) Reasoning Using Data: Two Old Ways and One New. Observational Studies Volume 7, Issue 1.\n  \n  \n    Tianyuan Zhou, Joao Sedoc, Jordan Rodu (2019) Getting in Shape: Word Embedding SubSpaces. Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence.\n  \n  \n    Jordan Rodu, Natalie Klein, Scott L. Brincat, Earl K. Miller, Robert E. Kass (2018) Detecting multivariate cross-correlation between brain regions. Journal of Neurophysiology 120(4):1962-1972.\n  \n  \n    Robert E. Kass et. al (2018) Computational Neuroscience: Mathematical and Statistical Perspectives. Annual Review of Statistics and Its Application Vol. 5:183-214.\n  \n  \n    Josue Orellana, Jordan Rodu, Robert E. Kass (2017) Population Vectors Can Provide Near Optimal Integration of Information. Neural Computation 29(8):2021-2029.\n  \n  \n    Jordan Rodu, Dean P. Foster, Weichen Wu, Lyle H. Ungar (2013) Using Regression for Spectral Estimation of HMMs. Statistical Language and Speech Processing - First International Conference. Proceedings. Lecture Notes in Computer Science 7978, Springer.\n  \n  \n    Paramveer S. Dhillon, Jordan Rodu, Michael Collins, Dean P. Foster, Lyle H. Ungar (2012) Spectral Dependency Parsing with Latent Variables. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.\n  \n  \n    Paramveer S. Dhillon, Jordan Rodu, Dean P. Foster, Lyle H. Ungar (2012) Two step CCA: a new spectral method for estimating vector models of words. Proceedings of the 29th International Coference on International Conference on Machine Learning.\n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Selected R packages\n\n\n\n\nPPA: a package that contains an example  shiny app for plot panel analysis\n\ngithub\n\n\n\nqqboxplot: an implementation of  the q-q boxplot\n\ngithub, CRAN"
  },
  {
    "objectID": "talks/french_academy_1901.html",
    "href": "talks/french_academy_1901.html",
    "title": "Adventures with Uranium Rays",
    "section": "",
    "text": "Abstract here\n\nSlides\nembed html or pdf slides here\n\n\nVideo"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Talks\nComing soon…"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Jordan Rodu",
    "section": "",
    "text": "Capstone\nUVA STAT 4996\nSpring 20, 23\n\n\n\nApplied Causal Inference\nUVA STAT 5350\nFall 22\n\n\n\nAdvanced Sports Analytics\nUVA STAT 4800\nFall 21, 22\nSpring 20, 21\n\n\n\nIntroduction to Sports Analytics\nUVA STAT 1800\nFall 19, 21\n\n\n\nStatistical Text Analysis\nUVA STAT 4559\nFall 20\n\n\n\nData Visualization and Presentation\nUVA STAT 4310\nFall 17, 18\nSpring 19\n\n\n\nStatistical Machine Learning (Graduate level)\nUVA STAT 5630\nFall 18\n\n\n\nStatistical Machine Learning (Undergraduate)\nUVA STAT 4630\nSpring 18"
  },
  {
    "objectID": "publications/MARA/index.html",
    "href": "publications/MARA/index.html",
    "title": "When black box algorithms are (not) appropriate",
    "section": "",
    "text": "In the 1980s a new, extraordinarily productive way of reasoning about algorithms emerged. In this paper, we introduce the term “outcome reasoning” to refer to this form of reasoning. Though outcome reasoning has come to dominate areas of data science, it has been under-discussed and its impact under-appreciated. For example, outcome reasoning is the primary way we reason about whether “black box” algorithms are performing well. In this paper we analyze outcome reasoning’s most common form (i.e., as “the common task framework”) and its limitations. We discuss why a large class of prediction-problems are inappropriate for outcome reasoning. As an example, we find the common task framework does not provide a foundation for the deployment of an algorithm in a real world situation. Building off of its core features, we identify a class of problems where this new form of reasoning can be used in deployment. We purposefully develop a novel framework so both technical and non-technical people can discuss and identify key features of their prediction problem and whether or not it is suitable for outcome reasoning."
  },
  {
    "objectID": "publications/MDCCA/index.html",
    "href": "publications/MDCCA/index.html",
    "title": "Detecting multivariate cross-correlation between brain regions",
    "section": "",
    "text": "The problem of identifying functional connectivity from multiple time series data recorded in each of two or more brain areas arises in many neuroscientific investigations. For a single stationary time series in each of two brain areas statistical tools such as cross-correlation and Granger causality may be applied. On the other hand, to examine multivariate interactions at a single time point, canonical correlation, which finds the linear combinations of signals that maximize the correlation, may be used. We report here a new method that produces interpretations much like these standard techniques and, in addition, 1) extends the idea of canonical correlation to 3-way arrays (with dimensionality number of signals by number of time points by number of trials), 2) allows for nonstationarity, 3) also allows for nonlinearity, 4) scales well as the number of signals increases, and 5) captures predictive relationships, as is done with Granger causality. We demonstrate the effectiveness of the method through simulation studies and illustrate by analyzing local field potentials recorded from a behaving primate."
  },
  {
    "objectID": "publications/computational-neuroscience-annual-reviews/index.html",
    "href": "publications/computational-neuroscience-annual-reviews/index.html",
    "title": "Computational Neuroscience: Mathematical and Statistical Perspectives",
    "section": "",
    "text": "Mathematical and statistical models have played important roles in neuroscience, especially by describing the electrical activity of neurons recorded individually, or collectively across large networks. As the field moves forward rapidly, new challenges are emerging. For maximal effectiveness, those working to advance computational neuroscience will need to appreciate and exploit the complementary strengths of mechanistic theory and the statistical paradigm."
  },
  {
    "objectID": "publications/getting-in-shape/index.html",
    "href": "publications/getting-in-shape/index.html",
    "title": "Getting in Shape: Word Embedding SubSpaces",
    "section": "",
    "text": "Many tasks in natural language processing require the alignment of word embeddings. Embedding alignment relies on the geometric properties of the manifold of word vectors. This paper focuses on supervised linear alignment and studies the relationship between the shape of the target embedding. We assess the performance of aligned word vectors on semantic similarity tasks and find that the isotropy of the target embedding is critical to the alignment. Furthermore, aligning with an isotropic noise can deliver satisfactory results. We provide a theoretical framework and guarantees which aid in the understanding of empirical results."
  },
  {
    "objectID": "publications/population-vectors/index.html",
    "href": "publications/population-vectors/index.html",
    "title": "Population Vectors Can Provide Near Optimal Integration of Information",
    "section": "",
    "text": "Much attention has been paid to the question of how Bayesian integration of information could be implemented by a simple neural mechanism. We show that population vectors based on point-process inputs combine evidence in a form that closely resembles Bayesian inference, with each input spike carrying information about the tuning of the input neuron. We also show that population vectors can combine information relatively accurately in the presence of noisy synaptic encoding of tuning curves."
  },
  {
    "objectID": "publications/qqboxplot/index.html",
    "href": "publications/qqboxplot/index.html",
    "title": "The q–q Boxplot",
    "section": "",
    "text": "Boxplots have become an extremely popular display of distribution summaries for collections of data, especially when we need to visualize summaries for several collections simultaneously. The whiskers in the boxplot show only the extent of the tails for most of the data (with outside values denoted separately); more detailed information about the shape of the tails, such as skewness and “weight” relative to a standard reference distribution, is much better displayed via quantile–quantile (q-q) plots. We incorporate the q-q plot’s tail information into the traditional boxplot by replacing the boxplot’s whiskers with the tails from a q-q plot, and display these tails with confidence bands for the tails that would be expected from the tails of the reference distribution. We describe the construction of the “q-q boxplot” and demonstrate its advantages over earlier proposed boxplot modifications on data from economics and neuroscience, which illustrate the q-q boxplots’ effectiveness in showing important tail behavior especially for large datasets. The package qqboxplot (an extension to the ggplot2 package) is available for the R programming language. Supplementary files for this article are available online."
  },
  {
    "objectID": "publications/reasoning-using-data/index.html",
    "href": "publications/reasoning-using-data/index.html",
    "title": "Reasoning Using Data: Two Old Ways and One New",
    "section": "",
    "text": "Instead of two cultures, the story of the last couple decades of data science is about the interplay between three different types of reasoning using data. Two of these types of reasoning were well known when Breiman wrote his Two Cultures paper – warranted reasoning (e.g., randomized trials and sampling) and model reasoning (e.g., linear models). Breiman, though he does not appear to have realized it fully, was in fact describing the dynamics arising in a data community that was making progress using the newest, third type of reasoning – outcome reasoning. In this commentary we clarify this dynamic a bit, and suggest some useful language for identifying and differentiating types of problems better suited for outcome reasoning."
  },
  {
    "objectID": "publications/spectral-dependency-parsing/index.html",
    "href": "publications/spectral-dependency-parsing/index.html",
    "title": "Spectral Dependency Parsing with Latent Variables",
    "section": "",
    "text": "Recently there has been substantial interest in using spectral methods to learn generative sequence models like HMMs. Spectral methods are attractive as they provide globally consistent estimates of the model parameters and are very fast and scalable, unlike EM methods, which can get stuck in local minima. In this paper, we present a novel extension of this class of spectral methods to learn dependency tree structures. We propose a simple yet powerful latent variable generative model for dependency parsing, and a spectral learning method to efficiently estimate it. As a pilot experimental evaluation, we use the spectral tree probabilities estimated by our model to re-rank the outputs of a near state-of-theart parser. Our approach gives us a moderate reduction in error of up to 4.6% over the baseline re-ranker."
  },
  {
    "objectID": "publications/translational-science-award/index.html",
    "href": "publications/translational-science-award/index.html",
    "title": "An analysis of the Clinical and Translational Science Award pilot project portfolio using data from Research Performance Progress Reports",
    "section": "",
    "text": "Pilot projects (“pilots”) are important for testing hypotheses in advance of investing more funds for full research studies. For some programs, such as Clinical and Translational Science Awards (CTSAs) supported by the National Center for Translational Sciences, pilots also make up a significant proportion of the research projects conducted with direct CTSA support. Unfortunately, administrative data on pilots are not typically captured in accessible databases. Though data on pilots are included in Research Performance Progress Reports, it is often difficult to extract, especially for large programs like the CTSAs where more than 600 pilots may be reported across all awardees annually. Data extraction challenges preclude analyses that could provide valuable information about pilots to researchers and administrators."
  },
  {
    "objectID": "publications/two-step-cca/index.html",
    "href": "publications/two-step-cca/index.html",
    "title": "Two step CCA: a new spectral method for estimating vector models of words",
    "section": "",
    "text": "Unlabeled data is often used to learn representations which can be used to supplement baseline features in a supervised learner. For example, for text applications where the words lie in a very high dimensional space (the size of the vocabulary), one can learn a low rank “dictionary” by an eigendecomposition of the word co-occurrence matrix (e.g. using PCA or CCA). In this paper, we present a new spectral method based on CCA to learn an eigenword dictionary. Our improved procedure computes two set of CCAs, the first one between the left and right contexts of the given word and the second one between the projections resulting from this CCA and the word itself. We prove theoretically that this two-step procedure has lower sample complexity than the simple single step procedure and also illustrate the empirical efficacy of our approach and the richness of representations learned by our Two Step CCA (TSCCA) procedure on the tasks of POS tagging and sentiment classification."
  },
  {
    "objectID": "publications/using-regression-spectral-estimation/index.html",
    "href": "publications/using-regression-spectral-estimation/index.html",
    "title": "Using Regression for Spectral Estimation of HMMs",
    "section": "",
    "text": "Hidden Markov Models (HMMs) are widely used to model discrete time series data, but the EM and Gibbs sampling methods used to estimate them are often slow or prone to get stuck in local minima. A more recent class of reduced-dimension spectral methods for estimating HMMs has attractive theoretical properties, but their finite sample size behavior has not been well characterized. We introduce a new spectral model for HMM estimation, a corresponding spectral bilinear regression model, and systematically compare them with a variety of competing simplified models, explaining when and why each method gives superior performance. Using regression to estimate HMMs has a number of advantages, allowing more powerful and flexible modeling."
  }
]